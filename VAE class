def sample(mu, log_var):
    std = torch.exp(0.5*log_var)
    eps = torch.randn_like(std)
    return mu + eps*std

class Encoder(nn.Module): 
    def __init__(self, conv_filt, hidden, input_channels=3): #conv_filt
        super(Encoder, self).__init__()
        
        self.layers = [] 
        
        conv_filts = [16, 32, 64, 128] #list of filters to run through later
        for i in range(2):
            conv_filts.append(conv_filt) #conv_filt=128
            
        #conv_filts = [16, 32, 64, 128, 128, 128]
        
            
        #make layers   
        filt_prev = input_channels #previous number of input channels, starting at 3
        
        for i, filt in enumerate(conv_filts): #prev was padding='valid' (no padding)
            if i==5:
                self.layers.append(nn.Conv2d(filt_prev, filt, 5, stride=1, padding=1)) #in channels, out channels, kernel size
                
            else:
                self.layers.append(nn.Conv2d(filt_prev, filt, 3, stride=1, padding=1)) #in channels, out channels, kernel size
            self.layers.append(nn.LeakyReLU(.2))# alpha parameter
            self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0)) #stride=1
            self.layers.append(nn.BatchNorm2d(filt))
            filt_prev = filt
            
        nconv = len(hidden) #is hidden [512, 256, 128, encoded_space_dim]?
        
        
        #convolutional in bottleneck instead of flattened
        #runs through each filter in hidden and does a 1x1 convolution
        for i in range(nconv):
            self.layers.append(nn.Conv2d(filt, hidden[i], 1, 1, padding=0)) #filt is 128, so 128->512
            self.layers.append(nn.LeakyReLU(.2)) #Tanh?
            self.layers.append(nn.BatchNorm2d(hidden[i]))
            filt = hidden[i]  #ends at batchnorm(encoded_space_dim)
            
        #self.layers.append(nn.Flatten(start_dim=1))
            
        self.layers = nn.ModuleList(self.layers)
            
    def forward(self, x): #list of encoding + hidden layers
        # run the input through the layers
        for layer in self.layers:
            x = layer(x)
        return x

class Decoder(nn.Module):
    def __init__(self, conv_filt, hidden, input_channels): #input channels = encoded_space_dim?
        super(Decoder, self).__init__()
        self.layers = []
        
        #self.layers.append(nn.Unflatten(dim=1, unflattened_size=(4, 5, 5))) 
        
        filt = input_channels #last layer of hidden- encoded_space_dim 
        #convolutional layers in bottleneck
        nconv = len(hidden) 
        for i in range(nconv):
            self.layers.append(nn.Conv2d(filt, hidden[i], 1, 1, padding=0)) 
            self.layers.append(nn.LeakyReLU(.2))
            self.layers.append(nn.BatchNorm2d(hidden[i]))
            filt = hidden[i]
            
        
        conv_filts = []  
        for i in range(1):
            conv_filts.append(conv_filt)
        conv_filts.extend([128, 64, 32, 16]) 
        
        filt_prev = filt #and filt = final element of hidden = 128
        for i, filt in enumerate(conv_filts): 
            #if i==4:
                #self.layers.append(nn.ConvTranspose2d(filt_prev, filt, 5, stride=2, padding=0))
                #kernel size 5 brings up to 447
            #else:
            self.layers.append(nn.ConvTranspose2d(filt_prev, filt, 3, stride=2, padding=0)) 
            self.layers.append(nn.LeakyReLU(.2))
            self.layers.append(nn.BatchNorm2d(filt))
            filt_prev=filt
  
            #do an if, else, and have if i=0 then kernel size = 5
        self.layers.append(nn.ConvTranspose2d(filt, 3, 5, stride=2, padding=0)) #try kernel 5 instead of upsample
        self.layers.append(nn.LeakyReLU(.2))
        self.layers.append(nn.BatchNorm2d(3))
        #self.layers.append(nn.Upsample((385,385)))
        self.layers.append(nn.Conv2d(3, 3, 2, 1)) 
        
        self.layers = nn.ModuleList(self.layers)
        
        
    def forward(self, x):
        # run the input through the layers
        for layer in self.layers:
            x = layer(x)
        x = torch.sigmoid(x)
        #x = transforms.CenterCrop(size=384)(x)
        return x
    
class BaseVAE(nn.Module):
    def __init__(self, conv_filt, hidden, input_channels=3):
        super(BaseVAE, self).__init__()

        self.conv_filt = conv_filt
        self.hidden    = hidden

        self.conv_mu  = nn.Conv2d(hidden[-1], hidden[-1], 1, 1) #[-1] is last item
        self.conv_sig = nn.Conv2d(hidden[-1], hidden[-1], 1, 1)
        
        self.flat_mu    = nn.Flatten()
        self.flat_sig   = nn.Flatten()

        self.encoder = Encoder(conv_filt, hidden, input_channels)
        self.decoder = Decoder(conv_filt, hidden[::-1], hidden[-1]) #[::-1] is all items, reversed
        #input channels for decoder is last entry of hidden

        self.type = ['VAE']

    def encode(self, x):
        enc = self.encoder(x)
        
        mu      = self.flat_mu(self.conv_mu(enc))
        log_var = self.flat_sig(self.conv_sig(enc))
        z       = sample(mu, log_var)

        return mu, log_var, z

    def decode(self, z):
        dec_inp = torch.reshape(z, (z.shape[0], self.hidden[-1], 5, 5)) #last two numbers are dimensions of img

        dec = self.decoder(dec_inp)

        return dec

    def forward(self, x):
        out = self.decode(self.encode(x)[2])

        return out
def mse_loss(y_true, y_pred):
    mse = torch.mean(torch.sum(torch.abs(y_true - y_pred), axis=(-1, -2)), axis=-1)#square vs abs
    return torch.mean(mse)

def kl_loss(mu, sig, mup, sig0=-4):
    kl = 0.5*torch.mean(-1 - sig + sig0 + (torch.square(mu-mup) + torch.exp(sig))/np.exp(sig0), axis=-1)
    return torch.mean(kl)

def loss_fcn(y_true, y_pred, mu, sig, mup, sig0=-4):
    mse = torch.mean(torch.sum(torch.abs(y_true - y_pred), axis=(-1, -2)), axis=-1)
    kl = 0.5*torch.mean(-1 - sig + sig0 + (torch.square(mu-mup) + torch.exp(sig))/np.exp(sig0), axis=-1)
    total_loss = .9*torch.mean(mse) + .1*torch.mean(kl)
    return total_loss #mup is mu predicted
    

lr = 1e-4 #Define optimizer for both encoder and decoder

torch.manual_seed(0)

encoded_space_dim = 4 #Initialize networks 

h = [128, 64, 32, encoded_space_dim]


vae = BaseVAE(conv_filt=256, hidden= h, input_channels=3)

params_to_optimize = [{'params': vae.parameters()}]

optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)

vae.to(device) #send to GPU
